<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Blog Sistemas Recomendadores</title>
    <link rel="stylesheet" href="index.css">
</head>
<body>
<div class="header">
    <h1>Sistemas Recomendadores - IIC3633</h1>
    <h2>Blog de Papers</h2>
    <h2>Sebastián Montoya</h2>
</div>
<ul>
    <li>
        <h1>Performance of Recommender algorithms on Top-N Recommendations tasks</h1>
        <h4>Paolo Cremonesi, Yehuda Koren and Roberto Turrin</h4>
        <p style="width: 50%"> This paper introduces the fact that the top-N recommendations should be evaluated over precision and recall
            instead of using the more classical metricas like RMSE or MAE. Mainly because they state the fact that
            a recommender system has good results in RMSE or MAE does not mean that it performs well for the top-N
            recommendations. So they propose the following, first of all eliminate the most popular or rated items
            so the systems are evaluated over the non-trivial recommendations, afterwards they use the train set for
            the Netflix dataset and for the test set they filter the Netflix test set only with the 5-star rated items.
            Then they take every item and predict the rating of it and 1000 items unrated by the user. After they define
            a hit or a succes if the position of the predicted item is in the first N position. Finally they explain
            every algorithm they are going to test and the final results where PureSVD performs the best in top-N
            recommendations.</p>
        <p style="width: 50%">
            I found this paper really interesting first because they are able to demonstrate that the most classical
            metrics are not always the best ones, which for me is a really strong fact. With that they try to look
            for a metric that was able to have good recommendations on the long tail head instead of the trivial
            recommendations, which is what a recommender system should target so it does not recommend the most popular
            or trivial items. Something I did not like in a visual perspective is that the analysis of the different
            charts is made on a totally different page so it is very hard to follow the explanation and afterwards looking
            to the charts. Something very particular is that they obtained a result they did not expected and even with that
            they are able to explain the results obtain. For me it is a really good and complete paper that explains every
            aspect of it.
        </p>
    </li>
    <li>
        <h1>Scalable Collaborative Filtering Approaches for Large Recommender Systems</h1>
        <h4>Gábor Takács, István Pilászy, Bottyán Németh and Domonkos Tikk</h4>
        <p style="width: 50%">
            This paper is about matrix factorization and different variations of this technique, along the paper
            the authors start explaining every variation and how it was different from the others and which problems
            did the variation resolve. Also in the beginning of the paper the authors show how they consider a correct
            classification for MF algorithms and from that they start explaining each algorithm.
        </p>
        <p style="width: 50%">
            Personally I did not liked this paper mainly because I did not found it interesting, for me it was a paper
            focused mainly in a mathematical part of algorithms. Therefore I really liked the fact that the authors
            made tests for every different algorithms they presented before, and compared them in various test and
            metric's comparisons. But generally was a hard reading paper, I had to do a lot of research because the authors
            present technical terms or algorithms, because the authors probably make the assumption that someone with a
            really good mathematical background is the one who is reading it. Therefore I do not feel they are able to
            explain the algorithms in a very simple way, in order that any person could get interested in this area by
            simply reading this paper.
        </p>
    </li>
    <li>
        <h1>Collaborative Filtering for Implicit Feedback Datasets</h1>
        <h4>Yifan Hu, Yehuda Koren and Chris Volinsky</h4>
        <p style="width: 50%">
            The authors of this paper, present a new algorithm for implicit feedback. As it is expected the authors
            first explain what is implicit feedback, that refers to all the actions that a user makes but without asking
            or receiving an explicit input. For example asking a survey if you liked or not a certain tv show, in the
            other hand implicit feedback could be the amount of time spent watching a specific tv show. For this they
            present a new algorithm that is based on the fact, that implicit feedback does not receive any negative inputs
            for example they can't know if a user disliked a program therefore they are able to suppose that if a user
            watch for a little time a tv show is probably because they did not like it. So they decide that instead of
            using a prediction of the rating, they are going to use a certain preference and a confidence on that amount
            of preference. So after some algebraic and mathematical optimizations they are able to propose a model that
            is able to predict a list of items for a user based on their activities with tv shows.
        </p>
        <p style="width: 50%">
            I really liked this paper because it explains how the implicit feedback works and they describe the main
            problems this type of feedback presents. The authors after introducing the main idea of the implicit feedback
            start to describe the multiple problems you can bump with and how to found or implement a solution for it.
            I found really interesting how they are able to create sort of new metrics based on the idea of preference and
            confidence. Also after reading the whole paper I notice that lots of the assumptions where made in the model,
            particularly the part where they set to zero all values less than 0.5, personally I found interesting analyzing
            this data and search a meaning for them because sometimes this type of outliers could contribute to design a
            better recommender system.
        </p>
    </li>
    <li>
        <h1>Slope One Predictors for Online Rating-Based Collaborative Filtering</h1>
        <h4>Daniel Lemire and Anna Maclachlan</h4>
        <p style="width: 50%">
            Mainly this paper talks about this new algorithm that is being proposed the Slope One, in the paper the
            authors get to explain the purposes a Collaborative Scheme should accomplish and how they start building
            this algorithms and which are their baseline for it. Further in the paper they get to explain the different
            types or variations that could be applied.
        </p>
        <p style="width: 50%">
            In my personal opinion I founded this paper really precise on what they are trying to present, so in this
            way the paper explains pretty concisely how the algorithm works and it variation. Also they include the
            variations in order for the reader to figure out which one is better and with that a comparison chart in
            work.
        </p>
        <p style="width: 50%">
            Something that I didn't like to much is the fact of the high level of mathematics being used in the paper
            definetely it limits the readers that could be able to understand the algorithm they are proposing. I think
            it would be interesting if in some way they could be able at first make a common reader understand how the
            algorithm works and afterwards introduce the hard mathematical part.
        </p>
    </li>
    <li>
        <h1>Collaborative Filtering Recommender Systems </h1>
        <h4>J. Ben Schafer, Dan Frankowski, Jon Herlocker and Shilad Sen</h4>
        <p style="width: 50%">
            This paper talks about how do collaborative filtering recommender systems work, in particular it starts
            telling the reader some examples of this type of recommender systems so the reader can start to get involve
            and recognize of what type of systems they are talking. Further in the paper it talks about
            how the users get involved with the systems and which are there duties when it comes to collaborative
            filtering. Afterwards it talks about the purpose or tasks that recommender systems try to acheive, for this
            it starts explaining the different types of algorithms depending on user or items and how they can be
            improved. For every algorithm also states the various practical problems that each one of them have.
            Finally it presents for the reader the different ways that you can evaluate a recommender system of this
            class, and afterwards the major tradeoffs you need to deal when developing this systems.
        </p>
        <p style="width: 50%">
            Personally I really liked how to the paper is structured because at first you get to understand the various
            algorithms and how do they works, so afterwards you are able to understand in a better way their limitations
            and because of that how important is to make a mixture of different recommender systems. Also something I
            really enjoyed is the part where it talks about how much information are the people willing to give in order
            to receive the best predictions, mostly because this is something people are talking about a lot given the
            global environment on this issue. I found really interesting that they have a section where they propose open
            questions so the reader is able to think and even question some things the authors propose.
        </p>
        <p style="width: 50%">
            As I have already stated I really like this paper therefore I founded challenging in some parts, and because
            of that I had to lookup for extra information when reading it. I also think that I would like more information
            on novelty and how it can improve your recommender system. But in general is a paper I really enjoyed and learned
            a lot from it.
        </p>
    </li>
</ul>
</body>
</html>